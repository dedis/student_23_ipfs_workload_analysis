# Part 2 - Measuring Wikipedia on IPFS

## Preparation Phase:
- `URL_crawler.py`: recursively crawls a webpage for unique links. The URL of the webpage and the recursion depth can be passed as arguments.
- `convert_URL_to_CID.py`

## Main loop:
- `process_CID.py`
- `repeated_measurements_all.py`

## Post-processing / Data Analysis
- `clean_unreachable_providers.py`
- `analyze_article_availability_IPFS.py`
- `analyze_article_availability_website.py`
- `analyze_number_of_providers.py`